----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           3,136
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19          [-1, 128, 28, 28]          73,728
      BatchNorm2d-20          [-1, 128, 28, 28]             256
             ReLU-21          [-1, 128, 28, 28]               0
           Conv2d-22          [-1, 128, 28, 28]         147,456
      BatchNorm2d-23          [-1, 128, 28, 28]             256
           Conv2d-24          [-1, 128, 28, 28]           8,192
      BatchNorm2d-25          [-1, 128, 28, 28]             256
             ReLU-26          [-1, 128, 28, 28]               0
       BasicBlock-27          [-1, 128, 28, 28]               0
           Conv2d-28          [-1, 128, 28, 28]         147,456
      BatchNorm2d-29          [-1, 128, 28, 28]             256
             ReLU-30          [-1, 128, 28, 28]               0
           Conv2d-31          [-1, 128, 28, 28]         147,456
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 256, 14, 14]         294,912
      BatchNorm2d-36          [-1, 256, 14, 14]             512
             ReLU-37          [-1, 256, 14, 14]               0
           Conv2d-38          [-1, 256, 14, 14]         589,824
      BatchNorm2d-39          [-1, 256, 14, 14]             512
           Conv2d-40          [-1, 256, 14, 14]          32,768
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
       BasicBlock-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 14, 14]         589,824
      BatchNorm2d-45          [-1, 256, 14, 14]             512
             ReLU-46          [-1, 256, 14, 14]               0
           Conv2d-47          [-1, 256, 14, 14]         589,824
      BatchNorm2d-48          [-1, 256, 14, 14]             512
             ReLU-49          [-1, 256, 14, 14]               0
       BasicBlock-50          [-1, 256, 14, 14]               0
           Conv2d-51            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-52            [-1, 512, 7, 7]           1,024
             ReLU-53            [-1, 512, 7, 7]               0
           Conv2d-54            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
           Conv2d-56            [-1, 512, 7, 7]         131,072
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       BasicBlock-59            [-1, 512, 7, 7]               0
           Conv2d-60            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-61            [-1, 512, 7, 7]           1,024
             ReLU-62            [-1, 512, 7, 7]               0
           Conv2d-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       BasicBlock-66            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
           Linear-68                 [-1, 1000]         513,000
================================================================
Total params: 11,683,240
Trainable params: 11,683,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 62.79
Params size (MB): 44.57
Estimated Total Size (MB): 107.55
----------------------------------------------------------------
#Params: 11.7M
19:29:44 --- Start training loop	training on: cuda
19:30:38 --- Epoch: 1	Train loss: 0.2131	Valid loss: 0.0479	Train accuracy: 98.50	Valid accuracy: 98.35
19:31:32 --- Epoch: 2	Train loss: 0.0497	Valid loss: 0.0393	Train accuracy: 98.95	Valid accuracy: 98.74
19:32:26 --- Epoch: 3	Train loss: 0.0336	Valid loss: 0.0376	Train accuracy: 99.19	Valid accuracy: 98.75
19:33:20 --- Epoch: 4	Train loss: 0.0232	Valid loss: 0.0322	Train accuracy: 99.27	Valid accuracy: 98.94
19:34:14 --- Epoch: 5	Train loss: 0.0182	Valid loss: 0.0362	Train accuracy: 99.25	Valid accuracy: 98.94
19:35:08 --- Epoch: 6	Train loss: 0.0152	Valid loss: 0.0354	Train accuracy: 99.30	Valid accuracy: 98.98
19:36:02 --- Epoch: 7	Train loss: 0.0148	Valid loss: 0.0457	Train accuracy: 99.24	Valid accuracy: 98.76
19:36:55 --- Epoch: 8	Train loss: 0.0121	Valid loss: 0.0364	Train accuracy: 99.52	Valid accuracy: 98.96
19:37:49 --- Epoch: 9	Train loss: 0.0140	Valid loss: 0.0393	Train accuracy: 99.40	Valid accuracy: 98.83
19:38:43 --- Epoch: 10	Train loss: 0.0121	Valid loss: 0.0439	Train accuracy: 99.27	Valid accuracy: 98.74
19:39:37 --- Epoch: 11	Train loss: 0.0099	Valid loss: 0.0379	Train accuracy: 99.55	Valid accuracy: 99.00
19:40:31 --- Epoch: 12	Train loss: 0.0087	Valid loss: 0.0389	Train accuracy: 99.60	Valid accuracy: 98.97
19:41:25 --- Epoch: 13	Train loss: 0.0110	Valid loss: 0.0394	Train accuracy: 99.52	Valid accuracy: 98.95
19:42:19 --- Epoch: 14	Train loss: 0.0091	Valid loss: 0.0431	Train accuracy: 99.50	Valid accuracy: 98.81
19:43:13 --- Epoch: 15	Train loss: 0.0091	Valid loss: 0.0446	Train accuracy: 99.34	Valid accuracy: 98.82
19:43:15 --- Time Stamp: 1650626984	top1 error: 0.0118	top5 error: 0.0000