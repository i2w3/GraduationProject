----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           3,136
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19          [-1, 128, 28, 28]          73,728
      BatchNorm2d-20          [-1, 128, 28, 28]             256
             ReLU-21          [-1, 128, 28, 28]               0
           Conv2d-22          [-1, 128, 28, 28]         147,456
      BatchNorm2d-23          [-1, 128, 28, 28]             256
           Conv2d-24          [-1, 128, 28, 28]           8,192
      BatchNorm2d-25          [-1, 128, 28, 28]             256
             ReLU-26          [-1, 128, 28, 28]               0
       BasicBlock-27          [-1, 128, 28, 28]               0
           Conv2d-28          [-1, 128, 28, 28]         147,456
      BatchNorm2d-29          [-1, 128, 28, 28]             256
             ReLU-30          [-1, 128, 28, 28]               0
           Conv2d-31          [-1, 128, 28, 28]         147,456
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 256, 14, 14]         294,912
      BatchNorm2d-36          [-1, 256, 14, 14]             512
             ReLU-37          [-1, 256, 14, 14]               0
           Conv2d-38          [-1, 256, 14, 14]         589,824
      BatchNorm2d-39          [-1, 256, 14, 14]             512
           Conv2d-40          [-1, 256, 14, 14]          32,768
      BatchNorm2d-41          [-1, 256, 14, 14]             512
             ReLU-42          [-1, 256, 14, 14]               0
       BasicBlock-43          [-1, 256, 14, 14]               0
           Conv2d-44          [-1, 256, 14, 14]         589,824
      BatchNorm2d-45          [-1, 256, 14, 14]             512
             ReLU-46          [-1, 256, 14, 14]               0
           Conv2d-47          [-1, 256, 14, 14]         589,824
      BatchNorm2d-48          [-1, 256, 14, 14]             512
             ReLU-49          [-1, 256, 14, 14]               0
       BasicBlock-50          [-1, 256, 14, 14]               0
           Conv2d-51            [-1, 512, 7, 7]       1,179,648
      BatchNorm2d-52            [-1, 512, 7, 7]           1,024
             ReLU-53            [-1, 512, 7, 7]               0
           Conv2d-54            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-55            [-1, 512, 7, 7]           1,024
           Conv2d-56            [-1, 512, 7, 7]         131,072
      BatchNorm2d-57            [-1, 512, 7, 7]           1,024
             ReLU-58            [-1, 512, 7, 7]               0
       BasicBlock-59            [-1, 512, 7, 7]               0
           Conv2d-60            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-61            [-1, 512, 7, 7]           1,024
             ReLU-62            [-1, 512, 7, 7]               0
           Conv2d-63            [-1, 512, 7, 7]       2,359,296
      BatchNorm2d-64            [-1, 512, 7, 7]           1,024
             ReLU-65            [-1, 512, 7, 7]               0
       BasicBlock-66            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0
           Linear-68                 [-1, 1000]         513,000
================================================================
Total params: 11,683,240
Trainable params: 11,683,240
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 62.79
Params size (MB): 44.57
Estimated Total Size (MB): 107.55
----------------------------------------------------------------
#Params: 11.7M
14:35:26 --- Start training loop	training on: cuda
14:36:27 --- Epoch: 1	Train loss: 0.3182	Valid loss: 0.1441	Train accuracy: 94.59	Valid accuracy: 95.41
14:37:27 --- Epoch: 2	Train loss: 0.1032	Valid loss: 0.0737	Train accuracy: 96.54	Valid accuracy: 97.60
14:38:27 --- Epoch: 3	Train loss: 0.0823	Valid loss: 0.0726	Train accuracy: 97.74	Valid accuracy: 97.60
14:39:27 --- Epoch: 4	Train loss: 0.0678	Valid loss: 0.0575	Train accuracy: 97.88	Valid accuracy: 98.14
14:40:27 --- Epoch: 5	Train loss: 0.0596	Valid loss: 0.0615	Train accuracy: 98.24	Valid accuracy: 98.00
14:41:26 --- Epoch: 6	Train loss: 0.0557	Valid loss: 0.0587	Train accuracy: 98.32	Valid accuracy: 98.08
14:42:25 --- Epoch: 7	Train loss: 0.0500	Valid loss: 0.0601	Train accuracy: 98.44	Valid accuracy: 98.10
14:43:25 --- Epoch: 8	Train loss: 0.0464	Valid loss: 0.0608	Train accuracy: 98.56	Valid accuracy: 98.14
14:44:24 --- Epoch: 9	Train loss: 0.0425	Valid loss: 0.0620	Train accuracy: 98.66	Valid accuracy: 98.08
14:45:24 --- Epoch: 10	Train loss: 0.0417	Valid loss: 0.0695	Train accuracy: 98.70	Valid accuracy: 97.94
14:46:23 --- Epoch: 11	Train loss: 0.0389	Valid loss: 0.0672	Train accuracy: 98.44	Valid accuracy: 98.09
14:47:23 --- Epoch: 12	Train loss: 0.0369	Valid loss: 0.0778	Train accuracy: 98.63	Valid accuracy: 97.75
14:48:22 --- Epoch: 13	Train loss: 0.0358	Valid loss: 0.0490	Train accuracy: 98.79	Valid accuracy: 98.41
14:49:27 --- Epoch: 14	Train loss: 0.0346	Valid loss: 0.0554	Train accuracy: 98.91	Valid accuracy: 98.36
14:50:32 --- Epoch: 15	Train loss: 0.0324	Valid loss: 0.0453	Train accuracy: 99.02	Valid accuracy: 98.58
14:50:35 --- Time Stamp: 1651041326	top1 error: 0.0142	top5 error: 0.0001
[0, 2, 4, 6, 8, 10, 12, 14]
